{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\ndf = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype={\"article_id\": str})\nprint(df.shape)\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-29T06:18:29.740606Z","iopub.execute_input":"2022-11-29T06:18:29.741025Z","iopub.status.idle":"2022-11-29T06:19:46.881934Z","shell.execute_reply.started":"2022-11-29T06:18:29.740976Z","shell.execute_reply":"2022-11-29T06:19:46.881247Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(31788324, 5)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        t_dat                                        customer_id  article_id  \\\n0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001   \n1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023   \n2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004   \n3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003   \n4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004   \n\n      price  sales_channel_id  \n0  0.050831                 2  \n1  0.030492                 2  \n2  0.015237                 2  \n3  0.016932                 2  \n4  0.016932                 2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>t_dat</th>\n      <th>customer_id</th>\n      <th>article_id</th>\n      <th>price</th>\n      <th>sales_channel_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>0663713001</td>\n      <td>0.050831</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-09-20</td>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>0541518023</td>\n      <td>0.030492</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>0505221004</td>\n      <td>0.015237</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>0685687003</td>\n      <td>0.016932</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-09-20</td>\n      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n      <td>0685687004</td>\n      <td>0.016932</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"t_dat\"] = pd.to_datetime(df[\"t_dat\"])\ndf[\"t_dat\"].max()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:19:46.883462Z","iopub.execute_input":"2022-11-29T06:19:46.883793Z","iopub.status.idle":"2022-11-29T06:19:51.571259Z","shell.execute_reply.started":"2022-11-29T06:19:46.883757Z","shell.execute_reply":"2022-11-29T06:19:51.570493Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Timestamp('2020-09-22 00:00:00')"},"metadata":{}}]},{"cell_type":"code","source":"active_articles = df.groupby(\"article_id\")[\"t_dat\"].max().reset_index()\nactive_articles = active_articles[active_articles[\"t_dat\"] >= \"2019-09-01\"].reset_index()\nactive_articles.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:19:51.572466Z","iopub.execute_input":"2022-11-29T06:19:51.572833Z","iopub.status.idle":"2022-11-29T06:19:56.229164Z","shell.execute_reply.started":"2022-11-29T06:19:51.572788Z","shell.execute_reply":"2022-11-29T06:19:56.228388Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(72581, 3)"},"metadata":{}}]},{"cell_type":"code","source":"df = df[df[\"article_id\"].isin(active_articles[\"article_id\"])].reset_index(drop=True)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:19:56.231027Z","iopub.execute_input":"2022-11-29T06:19:56.231433Z","iopub.status.idle":"2022-11-29T06:20:02.993258Z","shell.execute_reply.started":"2022-11-29T06:19:56.231387Z","shell.execute_reply":"2022-11-29T06:20:02.992524Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(29634404, 5)"},"metadata":{}}]},{"cell_type":"code","source":"df[\"week\"] = (df[\"t_dat\"].max() - df[\"t_dat\"]).dt.days // 7\ndf[\"week\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:20:02.994381Z","iopub.execute_input":"2022-11-29T06:20:02.994667Z","iopub.status.idle":"2022-11-29T06:20:04.457955Z","shell.execute_reply.started":"2022-11-29T06:20:02.994627Z","shell.execute_reply":"2022-11-29T06:20:04.456600Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"65     620104\n13     549443\n42     518403\n12     517428\n64     508664\n        ...  \n93     174190\n102    164298\n104    163143\n97     162580\n94     152807\nName: week, Length: 105, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\narticle_ids = np.concatenate([[\"placeholder\"], np.unique(df[\"article_id\"].values)])\n\nle_article = LabelEncoder()\nle_article.fit(article_ids)\ndf[\"article_id\"] = le_article.transform(df[\"article_id\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:20:04.461629Z","iopub.execute_input":"2022-11-29T06:20:04.462014Z","iopub.status.idle":"2022-11-29T06:20:47.691865Z","shell.execute_reply.started":"2022-11-29T06:20:04.461973Z","shell.execute_reply":"2022-11-29T06:20:47.691046Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"WEEK_HIST_MAX = 5\n\ndef create_dataset(df, week):\n    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n    \n    target_df = df[df[\"week\"] == week]\n    target_df = target_df.groupby(\"customer_id\").agg({\"article_id\": list}).reset_index()\n    target_df.rename(columns={\"article_id\": \"target\"}, inplace=True)\n    target_df[\"week\"] = week\n    \n    return target_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n\nval_weeks = [0]\ntrain_weeks = [1, 2, 3, 4]\n\n\nval_df = pd.concat([create_dataset(df, w) for w in val_weeks]).reset_index(drop=True)\ntrain_df = pd.concat([create_dataset(df, w) for w in train_weeks]).reset_index(drop=True)\ntrain_df.shape, val_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:20:47.693384Z","iopub.execute_input":"2022-11-29T06:20:47.693659Z","iopub.status.idle":"2022-11-29T06:21:19.188158Z","shell.execute_reply.started":"2022-11-29T06:20:47.693622Z","shell.execute_reply":"2022-11-29T06:21:19.187450Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"((300129, 5), (68984, 5))"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\nfrom tqdm import tqdm\n\nclass HMDataset(Dataset):\n    def __init__(self, df, seq_len, is_test=False):\n        self.df = df.reset_index(drop=True)\n        self.seq_len = seq_len\n        self.is_test = is_test\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        if self.is_test:\n            target = torch.zeros(2).float()\n        else:\n            if not row.target:\n                target = torch.tensor([0]).int()\n            else:\n                rand_target = np.random.choice(row.target,1)\n                target = torch.tensor(rand_target).squeeze().int()\n\n            \n        article_hist = torch.zeros(self.seq_len).long()\n        week_hist = torch.ones(self.seq_len).float()\n        \n        \n        if isinstance(row.article_id, list):\n            if len(row.article_id) >= self.seq_len:\n                article_hist = torch.LongTensor(row.article_id[-self.seq_len:])\n                week_hist = (torch.LongTensor(row.week_history[-self.seq_len:]) - row.week)/WEEK_HIST_MAX/2\n            else:\n                article_hist[-len(row.article_id):] = torch.LongTensor(row.article_id)\n                week_hist[-len(row.article_id):] = (torch.LongTensor(row.week_history) - row.week)/WEEK_HIST_MAX/2\n                \n        return article_hist, week_hist, target\n    \nHMDataset(val_df, 64)[2]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:19.189261Z","iopub.execute_input":"2022-11-29T06:21:19.189504Z","iopub.status.idle":"2022-11-29T06:21:20.681107Z","shell.execute_reply.started":"2022-11-29T06:21:19.189469Z","shell.execute_reply":"2022-11-29T06:21:20.680359Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,  1310, 31011,  5922, 59838,\n         31013,  7950, 52530, 31012]),\n tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n         1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n         0.1000]),\n tensor(14652, dtype=torch.int32))"},"metadata":{}}]},{"cell_type":"code","source":"def adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 6:\n        lr = 1e-3\n    elif epoch < 9:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:20.682366Z","iopub.execute_input":"2022-11-29T06:21:20.683707Z","iopub.status.idle":"2022-11-29T06:21:20.690288Z","shell.execute_reply.started":"2022-11-29T06:21:20.683668Z","shell.execute_reply":"2022-11-29T06:21:20.689459Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:20.693061Z","iopub.execute_input":"2022-11-29T06:21:20.693379Z","iopub.status.idle":"2022-11-29T06:21:20.700780Z","shell.execute_reply.started":"2022-11-29T06:21:20.693338Z","shell.execute_reply":"2022-11-29T06:21:20.700003Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class HierarchicalSoftmax(nn.Module):\n    def __init__(self, ntokens, nhid, ntokens_per_class = None):\n        super(HierarchicalSoftmax, self).__init__()\n\n        # Parameters\n        self.ntokens = ntokens#the number of ouput.(72582)\n        self.nhid = nhid#dimension: the same length of customer dimension.(512)\n\n        self.ntokens_per_class = ntokens_per_class#how many children one intermidiate node.(20)\n\n        self.nclasses = int(np.ceil(self.ntokens * 1. / self.ntokens_per_class))#intermidiate nodes.(3630)\n        self.ntokens_actual = self.nclasses * self.ntokens_per_class#72600\n\n        self.layer_top_W = nn.Parameter(torch.FloatTensor(self.nhid, self.nclasses), requires_grad=True)\n        self.layer_top_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n\n        self.layer_bottom_W = nn.Parameter(torch.FloatTensor(self.ntokens_per_class, self.nhid), requires_grad=True)\n        self.layer_bottom_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n\n        self.init_weights()\n\n    def init_weights(self):\n\n        initrange = 0.1\n        self.layer_top_W.data.uniform_(-initrange, initrange)\n        self.layer_top_b.data.fill_(0)\n        self.layer_bottom_W.data.uniform_(-initrange, initrange)\n        self.layer_bottom_b.data.fill_(0)\n\n\n    def forward(self, inputs):\n        labels = torch.arange(self.ntokens_actual)###72600 \n        batch_size, d = inputs.size()\n\n        label_position_top = (labels / self.ntokens_per_class).long()#which position is the top layer.###[0,0,..,0,....,3659,3659]\n        label_position_bottom = (labels % self.ntokens_per_class).long()#which position is the bottom layer.###[0,1,2,..,19,1,2,...,19,..]\n        \n        layer_top_logits = torch.matmul(inputs, self.layer_top_W) + self.layer_top_b###[256, 3630]\n\n        multi_bias = self.layer_bottom_b[label_position_bottom].repeat(batch_size,1)###[256,72600]\n        \n        layer_bottom_logits = torch.matmul(inputs,self.layer_bottom_W[label_position_bottom].T) + multi_bias###[256,72600]\n\n        layer_top_logits = layer_top_logits.repeat_interleave(self.ntokens_per_class,dim=1)###[256,72600]#match the top classes and the bottom classes.\n        \n        target_logits = torch.add(layer_top_logits,layer_bottom_logits)#get the final logits\n\n        return target_logits\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:20.701676Z","iopub.execute_input":"2022-11-29T06:21:20.702488Z","iopub.status.idle":"2022-11-29T06:21:20.715224Z","shell.execute_reply.started":"2022-11-29T06:21:20.702450Z","shell.execute_reply":"2022-11-29T06:21:20.714506Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class HMModel(nn.Module):\n    def __init__(self, article_shape):\n        super(HMModel, self).__init__()\n        \n        self.article_emb = nn.Embedding(article_shape[0], embedding_dim=article_shape[1])\n        self.hier = HierarchicalSoftmax(72582, 512,ntokens_per_class = 20)\n        \n    def forward(self, inputs):\n        article_hist, week_hist = inputs[0], inputs[1]\n        x = self.article_emb(article_hist)\n        x = F.normalize(x, dim=2)###[256, 16, 512]\n        \n        x, indices = x.max(axis=1)##customer_emb[256,512]\n\n        ###get logits rather than probability to generate loss function.\n        \n        logits = self.hier(x)\n        logits = logits[:,:72582]#remove virtual leaves.\n\n        return logits\n    \n    \nmodel = HMModel((len(le_article.classes_), 512))\nmodel = model.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:20.716236Z","iopub.execute_input":"2022-11-29T06:21:20.716957Z","iopub.status.idle":"2022-11-29T06:21:24.280501Z","shell.execute_reply.started":"2022-11-29T06:21:20.716919Z","shell.execute_reply":"2022-11-29T06:21:24.279713Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import sys\n\ndef calc_map(topk_preds, target_array, k=12):\n    metric = []\n    tp, fp = 0, 0\n    \n    for pred in topk_preds:\n        if target_array[pred]:\n            tp += 1\n            metric.append(tp/(tp + fp))\n        else:\n            fp += 1\n            \n    return np.sum(metric) / min(k, target_array.sum())\n\ndef read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\n\ndef validate(model, val_loader, k=12):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    maps = []\n    \n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            logits = model(inputs)\n\n            _, indices = torch.topk(logits, k, dim=1)\n\n            indices = indices.detach().cpu().numpy()\n            target = target.detach().cpu().numpy()\n            \n            for i in range(indices.shape[0]):\n                maps.append(calc_map(indices[i], target[i]))\n        \n    \n    return np.mean(maps)\n\nSEQ_LEN = 16\n\nBS = 256\nNW = 8\n\nval_dataset = HMDataset(val_df, SEQ_LEN)\nval_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=NW,\n                          pin_memory=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:24.281999Z","iopub.execute_input":"2022-11-29T06:21:24.282263Z","iopub.status.idle":"2022-11-29T06:21:24.300014Z","shell.execute_reply.started":"2022-11-29T06:21:24.282227Z","shell.execute_reply":"2022-11-29T06:21:24.299092Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train and validate","metadata":{}},{"cell_type":"code","source":"def dice_loss(y_pred, y_true):\n    y_pred = y_pred.sigmoid()\n    intersect = (y_true*y_pred).sum(axis=1)\n    \n    return 1 - (intersect/(intersect + y_true.sum(axis=1) + y_pred.sum(axis=1))).mean()\n\n\ndef train(model, train_loader, val_loader, epochs):\n    np.random.seed(SEED)\n    \n    optimizer = get_optimizer(model)\n    scaler = torch.cuda.amp.GradScaler()\n    \n    criterion = torch.nn.functional.cross_entropy\n    \n    for e in range(epochs):\n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            \n            with torch.cuda.amp.autocast():\n                logits = model(inputs)\n#                 print(logits.shape)\n#                 print(logits)\n#                 print(target.shape)\n#                 print(target)\n#                 return ###\n                loss = criterion(logits, target.long())\n            #loss.backward()\n            scaler.scale(loss).backward()\n            #optimizer.step()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            loss_list.append(loss.detach().cpu().item())\n            \n            avg_loss = np.round(100*np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n            \n    return model\n\n\nMODEL_NAME = \"exp001\"\nSEED = 0\n\ntrain_dataset = HMDataset(train_df, SEQ_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\n\nmodel = train(model, train_loader, val_loader, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:21:24.301502Z","iopub.execute_input":"2022-11-29T06:21:24.302041Z","iopub.status.idle":"2022-11-29T06:37:56.623532Z","shell.execute_reply.started":"2022-11-29T06:21:24.302004Z","shell.execute_reply":"2022-11-29T06:37:56.622646Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 1093.7785 lr: 5e-05: 100%|██████████| 1172/1172 [01:38<00:00, 11.85it/s]\nEpoch 2 Loss: 1013.3217 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.73it/s]\nEpoch 3 Loss: 1006.2875 lr: 0.001: 100%|██████████| 1172/1172 [01:40<00:00, 11.72it/s]\nEpoch 4 Loss: 1004.8955 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.73it/s]\nEpoch 5 Loss: 1003.6794 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.81it/s]\nEpoch 6 Loss: 1002.1637 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.84it/s]\nEpoch 7 Loss: 999.4369 lr: 0.0001: 100%|██████████| 1172/1172 [01:38<00:00, 11.84it/s]\nEpoch 8 Loss: 998.6596 lr: 0.0001: 100%|██████████| 1172/1172 [01:39<00:00, 11.83it/s]\nEpoch 9 Loss: 998.6075 lr: 0.0001: 100%|██████████| 1172/1172 [01:38<00:00, 11.88it/s]\nEpoch 10 Loss: 997.993 lr: 1e-05: 100%|██████████| 1172/1172 [01:38<00:00, 11.89it/s] \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Finetune with more recent data for submission (include validation set)","metadata":{}},{"cell_type":"code","source":"train_dataset = HMDataset(train_df[train_df[\"week\"] < 4].append(val_df), SEQ_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\n\nmodel = train(model, train_loader, val_loader, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:37:56.625672Z","iopub.execute_input":"2022-11-29T06:37:56.626263Z","iopub.status.idle":"2022-11-29T06:54:10.053546Z","shell.execute_reply.started":"2022-11-29T06:37:56.626223Z","shell.execute_reply":"2022-11-29T06:54:10.052478Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 994.2746 lr: 5e-05: 100%|██████████| 1160/1160 [01:37<00:00, 11.85it/s]\nEpoch 2 Loss: 994.0558 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.91it/s]\nEpoch 3 Loss: 991.9912 lr: 0.001: 100%|██████████| 1160/1160 [01:36<00:00, 11.96it/s]\nEpoch 4 Loss: 989.718 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s] \nEpoch 5 Loss: 987.1725 lr: 0.001: 100%|██████████| 1160/1160 [01:36<00:00, 12.05it/s]\nEpoch 6 Loss: 984.365 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.85it/s] \nEpoch 7 Loss: 980.8309 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s]\nEpoch 8 Loss: 979.9418 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.87it/s]\nEpoch 9 Loss: 979.8323 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s]\nEpoch 10 Loss: 979.0787 lr: 1e-05: 100%|██████████| 1160/1160 [01:37<00:00, 11.94it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv').drop(\"prediction\", axis=1)\nprint(test_df.shape)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:54:10.058149Z","iopub.execute_input":"2022-11-29T06:54:10.059579Z","iopub.status.idle":"2022-11-29T06:54:15.542296Z","shell.execute_reply.started":"2022-11-29T06:54:10.059513Z","shell.execute_reply":"2022-11-29T06:54:15.541386Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(1371980, 1)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                         customer_id\n0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...\n1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...\n2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...\n3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...\n4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def create_test_dataset(test_df):\n    week = -1\n    test_df[\"week\"] = week\n    \n    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n    \n    \n    return test_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n\ntest_df = create_test_dataset(test_df)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:54:15.543800Z","iopub.execute_input":"2022-11-29T06:54:15.544063Z","iopub.status.idle":"2022-11-29T06:54:21.957136Z","shell.execute_reply.started":"2022-11-29T06:54:15.544019Z","shell.execute_reply":"2022-11-29T06:54:21.956433Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                         customer_id  week article_id  \\\n0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...    -1     [7154]   \n1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...    -1        NaN   \n2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -1    [46435]   \n3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...    -1        NaN   \n4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...    -1        NaN   \n\n  week_history  \n0          [2]  \n1          NaN  \n2          [1]  \n3          NaN  \n4          NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>week_history</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n      <td>-1</td>\n      <td>[7154]</td>\n      <td>[2]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>-1</td>\n      <td>[46435]</td>\n      <td>[1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df[\"article_id\"].isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:54:21.958305Z","iopub.execute_input":"2022-11-29T06:54:21.958584Z","iopub.status.idle":"2022-11-29T06:54:22.013981Z","shell.execute_reply.started":"2022-11-29T06:54:21.958529Z","shell.execute_reply":"2022-11-29T06:54:22.012856Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"0.8008965145264508"},"metadata":{}}]},{"cell_type":"code","source":"test_ds = HMDataset(test_df, SEQ_LEN, is_test=True)\ntest_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                          pin_memory=False, drop_last=False)\n\n\ndef inference(model, loader, k=12):\n    model.eval()\n    \n    tbar = tqdm(loader, file=sys.stdout)\n    \n    preds = []\n    \n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            logits = model(inputs)\n\n            _, indices = torch.topk(logits, k, dim=1)\n\n            indices = indices.detach().cpu().numpy()\n            target = target.detach().cpu().numpy()\n\n            for i in range(indices.shape[0]):\n                preds.append(\" \".join(list(le_article.inverse_transform(indices[i]))))\n        \n    \n    return preds\n\n\ntest_df[\"prediction\"] = inference(model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:54:22.015428Z","iopub.execute_input":"2022-11-29T06:54:22.015726Z","iopub.status.idle":"2022-11-29T07:28:57.819641Z","shell.execute_reply.started":"2022-11-29T06:54:22.015689Z","shell.execute_reply":"2022-11-29T07:28:57.818068Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 5360/5360 [34:35<00:00,  2.58it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df.to_csv(\"submission.csv\", index=False, columns=[\"customer_id\", \"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-29T06:18:21.024843Z","iopub.status.idle":"2022-11-29T06:18:21.025741Z","shell.execute_reply.started":"2022-11-29T06:18:21.025498Z","shell.execute_reply":"2022-11-29T06:18:21.025522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2022-11-29T07:29:44.396461Z","iopub.execute_input":"2022-11-29T07:29:44.397447Z","iopub.status.idle":"2022-11-29T07:29:44.416828Z","shell.execute_reply.started":"2022-11-29T07:29:44.397391Z","shell.execute_reply":"2022-11-29T07:29:44.415843Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                               customer_id  week  \\\n0        00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...    -1   \n1        0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...    -1   \n2        000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -1   \n3        00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...    -1   \n4        00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...    -1   \n...                                                    ...   ...   \n1371975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...    -1   \n1371976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...    -1   \n1371977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...    -1   \n1371978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...    -1   \n1371979  ffffd9ac14e89946416d80e791d064701994755c3ab686...    -1   \n\n                                        article_id        week_history  \\\n0                                           [7154]                 [2]   \n1                                              NaN                 NaN   \n2                                          [46435]                 [1]   \n3                                              NaN                 NaN   \n4                                              NaN                 NaN   \n...                                            ...                 ...   \n1371975  [27463, 28961, 33376, 45860, 49128, 6056]  [2, 2, 2, 2, 2, 2]   \n1371976                                        NaN                 NaN   \n1371977               [21885, 66983, 46532, 39429]        [2, 2, 2, 1]   \n1371978                                        NaN                 NaN   \n1371979                                        NaN                 NaN   \n\n                                                prediction  \n0        0751471042 0751471041 0751471043 0751471037 07...  \n1        0915526002 0915611003 0915529001 0915453004 09...  \n2        0762846003 0915453003 0762856001 0915611003 08...  \n3        0915526002 0915611003 0915529001 0915453004 09...  \n4        0915526002 0915611003 0915529001 0915453004 09...  \n...                                                    ...  \n1371975  0915453004 0863581002 0915611003 0915529003 08...  \n1371976  0915526002 0915611003 0915529001 0915453004 09...  \n1371977  0762846027 0762853002 0762856008 0762846036 07...  \n1371978  0915526002 0915611003 0915529001 0915453004 09...  \n1371979  0915526002 0915611003 0915529001 0915453004 09...  \n\n[1371980 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>week</th>\n      <th>article_id</th>\n      <th>week_history</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n      <td>-1</td>\n      <td>[7154]</td>\n      <td>[2]</td>\n      <td>0751471042 0751471041 0751471043 0751471037 07...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n      <td>-1</td>\n      <td>[46435]</td>\n      <td>[1]</td>\n      <td>0762846003 0915453003 0762856001 0915611003 08...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1371975</th>\n      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n      <td>-1</td>\n      <td>[27463, 28961, 33376, 45860, 49128, 6056]</td>\n      <td>[2, 2, 2, 2, 2, 2]</td>\n      <td>0915453004 0863581002 0915611003 0915529003 08...</td>\n    </tr>\n    <tr>\n      <th>1371976</th>\n      <td>ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n    <tr>\n      <th>1371977</th>\n      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n      <td>-1</td>\n      <td>[21885, 66983, 46532, 39429]</td>\n      <td>[2, 2, 2, 1]</td>\n      <td>0762846027 0762853002 0762856008 0762846036 07...</td>\n    </tr>\n    <tr>\n      <th>1371978</th>\n      <td>ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n    <tr>\n      <th>1371979</th>\n      <td>ffffd9ac14e89946416d80e791d064701994755c3ab686...</td>\n      <td>-1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1371980 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}