{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-29T06:18:29.741025Z",
     "iopub.status.busy": "2022-11-29T06:18:29.740606Z",
     "iopub.status.idle": "2022-11-29T06:19:46.881934Z",
     "shell.execute_reply": "2022-11-29T06:19:46.881247Z",
     "shell.execute_reply.started": "2022-11-29T06:18:29.740976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31788324, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0663713001</td>\n",
       "      <td>0.050831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0541518023</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0505221004</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687003</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>00007d2de826758b65a93dd24ce629ed66842531df6699...</td>\n",
       "      <td>0685687004</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t_dat                                        customer_id  article_id  \\\n",
       "0  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0663713001   \n",
       "1  2018-09-20  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...  0541518023   \n",
       "2  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0505221004   \n",
       "3  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687003   \n",
       "4  2018-09-20  00007d2de826758b65a93dd24ce629ed66842531df6699...  0685687004   \n",
       "\n",
       "      price  sales_channel_id  \n",
       "0  0.050831                 2  \n",
       "1  0.030492                 2  \n",
       "2  0.015237                 2  \n",
       "3  0.016932                 2  \n",
       "4  0.016932                 2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype={\"article_id\": str})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:19:46.883793Z",
     "iopub.status.busy": "2022-11-29T06:19:46.883462Z",
     "iopub.status.idle": "2022-11-29T06:19:51.571259Z",
     "shell.execute_reply": "2022-11-29T06:19:51.570493Z",
     "shell.execute_reply.started": "2022-11-29T06:19:46.883757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-09-22 00:00:00')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"t_dat\"] = pd.to_datetime(df[\"t_dat\"])\n",
    "df[\"t_dat\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:19:51.572833Z",
     "iopub.status.busy": "2022-11-29T06:19:51.572466Z",
     "iopub.status.idle": "2022-11-29T06:19:56.229164Z",
     "shell.execute_reply": "2022-11-29T06:19:56.228388Z",
     "shell.execute_reply.started": "2022-11-29T06:19:51.572788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72581, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_articles = df.groupby(\"article_id\")[\"t_dat\"].max().reset_index()\n",
    "active_articles = active_articles[active_articles[\"t_dat\"] >= \"2019-09-01\"].reset_index()\n",
    "active_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:19:56.231433Z",
     "iopub.status.busy": "2022-11-29T06:19:56.231027Z",
     "iopub.status.idle": "2022-11-29T06:20:02.993258Z",
     "shell.execute_reply": "2022-11-29T06:20:02.992524Z",
     "shell.execute_reply.started": "2022-11-29T06:19:56.231387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29634404, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"article_id\"].isin(active_articles[\"article_id\"])].reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:20:02.994667Z",
     "iopub.status.busy": "2022-11-29T06:20:02.994381Z",
     "iopub.status.idle": "2022-11-29T06:20:04.457955Z",
     "shell.execute_reply": "2022-11-29T06:20:04.456600Z",
     "shell.execute_reply.started": "2022-11-29T06:20:02.994627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65     620104\n",
       "13     549443\n",
       "42     518403\n",
       "12     517428\n",
       "64     508664\n",
       "        ...  \n",
       "93     174190\n",
       "102    164298\n",
       "104    163143\n",
       "97     162580\n",
       "94     152807\n",
       "Name: week, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"week\"] = (df[\"t_dat\"].max() - df[\"t_dat\"]).dt.days // 7\n",
    "df[\"week\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:20:04.462014Z",
     "iopub.status.busy": "2022-11-29T06:20:04.461629Z",
     "iopub.status.idle": "2022-11-29T06:20:47.691865Z",
     "shell.execute_reply": "2022-11-29T06:20:47.691046Z",
     "shell.execute_reply.started": "2022-11-29T06:20:04.461973Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "article_ids = np.concatenate([[\"placeholder\"], np.unique(df[\"article_id\"].values)])\n",
    "\n",
    "le_article = LabelEncoder()\n",
    "le_article.fit(article_ids)\n",
    "df[\"article_id\"] = le_article.transform(df[\"article_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:20:47.693659Z",
     "iopub.status.busy": "2022-11-29T06:20:47.693384Z",
     "iopub.status.idle": "2022-11-29T06:21:19.188158Z",
     "shell.execute_reply": "2022-11-29T06:21:19.187450Z",
     "shell.execute_reply.started": "2022-11-29T06:20:47.693622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300129, 5), (68984, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEEK_HIST_MAX = 5\n",
    "\n",
    "def create_dataset(df, week):\n",
    "    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n",
    "    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n",
    "    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n",
    "    \n",
    "    target_df = df[df[\"week\"] == week]\n",
    "    target_df = target_df.groupby(\"customer_id\").agg({\"article_id\": list}).reset_index()\n",
    "    target_df.rename(columns={\"article_id\": \"target\"}, inplace=True)\n",
    "    target_df[\"week\"] = week\n",
    "    \n",
    "    return target_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "val_weeks = [0]\n",
    "train_weeks = [1, 2, 3, 4]\n",
    "\n",
    "\n",
    "val_df = pd.concat([create_dataset(df, w) for w in val_weeks]).reset_index(drop=True)\n",
    "train_df = pd.concat([create_dataset(df, w) for w in train_weeks]).reset_index(drop=True)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:19.189504Z",
     "iopub.status.busy": "2022-11-29T06:21:19.189261Z",
     "iopub.status.idle": "2022-11-29T06:21:20.681107Z",
     "shell.execute_reply": "2022-11-29T06:21:20.680359Z",
     "shell.execute_reply.started": "2022-11-29T06:21:19.189469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,  1310, 31011,  5922, 59838,\n",
       "         31013,  7950, 52530, 31012]),\n",
       " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]),\n",
       " tensor(14652, dtype=torch.int32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HMDataset(Dataset):\n",
    "    def __init__(self, df, seq_len, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.seq_len = seq_len\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        if self.is_test:\n",
    "            target = torch.zeros(2).float()\n",
    "        else:\n",
    "            if not row.target:\n",
    "                target = torch.tensor([0]).int()\n",
    "            else:\n",
    "                rand_target = np.random.choice(row.target,1)\n",
    "                target = torch.tensor(rand_target).squeeze().int()\n",
    "\n",
    "            \n",
    "        article_hist = torch.zeros(self.seq_len).long()\n",
    "        week_hist = torch.ones(self.seq_len).float()\n",
    "        \n",
    "        \n",
    "        if isinstance(row.article_id, list):\n",
    "            if len(row.article_id) >= self.seq_len:\n",
    "                article_hist = torch.LongTensor(row.article_id[-self.seq_len:])\n",
    "                week_hist = (torch.LongTensor(row.week_history[-self.seq_len:]) - row.week)/WEEK_HIST_MAX/2\n",
    "            else:\n",
    "                article_hist[-len(row.article_id):] = torch.LongTensor(row.article_id)\n",
    "                week_hist[-len(row.article_id):] = (torch.LongTensor(row.week_history) - row.week)/WEEK_HIST_MAX/2\n",
    "                \n",
    "        return article_hist, week_hist, target\n",
    "    \n",
    "HMDataset(val_df, 64)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:20.683707Z",
     "iopub.status.busy": "2022-11-29T06:21:20.682366Z",
     "iopub.status.idle": "2022-11-29T06:21:20.690288Z",
     "shell.execute_reply": "2022-11-29T06:21:20.689459Z",
     "shell.execute_reply.started": "2022-11-29T06:21:20.683668Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch < 1:\n",
    "        lr = 5e-5\n",
    "    elif epoch < 6:\n",
    "        lr = 1e-3\n",
    "    elif epoch < 9:\n",
    "        lr = 1e-4\n",
    "    else:\n",
    "        lr = 1e-5\n",
    "\n",
    "    for p in optimizer.param_groups:\n",
    "        p['lr'] = lr\n",
    "    return lr\n",
    "    \n",
    "def get_optimizer(net):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n",
    "                                 eps=1e-08)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:20.693379Z",
     "iopub.status.busy": "2022-11-29T06:21:20.693061Z",
     "iopub.status.idle": "2022-11-29T06:21:20.700780Z",
     "shell.execute_reply": "2022-11-29T06:21:20.700003Z",
     "shell.execute_reply.started": "2022-11-29T06:21:20.693338Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:20.702488Z",
     "iopub.status.busy": "2022-11-29T06:21:20.701676Z",
     "iopub.status.idle": "2022-11-29T06:21:20.715224Z",
     "shell.execute_reply": "2022-11-29T06:21:20.714506Z",
     "shell.execute_reply.started": "2022-11-29T06:21:20.702450Z"
    }
   },
   "outputs": [],
   "source": [
    "class HierarchicalSoftmax(nn.Module):\n",
    "    def __init__(self, ntokens, nhid, ntokens_per_class = None):\n",
    "        super(HierarchicalSoftmax, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.ntokens = ntokens#the number of ouput.(72582)\n",
    "        self.nhid = nhid#dimension: the same length of customer dimension.(512)\n",
    "\n",
    "        self.ntokens_per_class = ntokens_per_class#how many children one intermidiate node.(20)\n",
    "\n",
    "        self.nclasses = int(np.ceil(self.ntokens * 1. / self.ntokens_per_class))#intermidiate nodes.(3630)\n",
    "        self.ntokens_actual = self.nclasses * self.ntokens_per_class#72600\n",
    "\n",
    "        self.layer_top_W = nn.Parameter(torch.FloatTensor(self.nhid, self.nclasses), requires_grad=True)\n",
    "        self.layer_top_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n",
    "\n",
    "        self.layer_bottom_W = nn.Parameter(torch.FloatTensor(self.ntokens_per_class, self.nhid), requires_grad=True)\n",
    "        self.layer_bottom_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "\n",
    "        initrange = 0.1\n",
    "        self.layer_top_W.data.uniform_(-initrange, initrange)\n",
    "        self.layer_top_b.data.fill_(0)\n",
    "        self.layer_bottom_W.data.uniform_(-initrange, initrange)\n",
    "        self.layer_bottom_b.data.fill_(0)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        labels = torch.arange(self.ntokens_actual)###72600 \n",
    "        batch_size, d = inputs.size()\n",
    "\n",
    "        label_position_top = (labels / self.ntokens_per_class).long()#which position is the top layer.###[0,0,..,0,....,3659,3659]\n",
    "        label_position_bottom = (labels % self.ntokens_per_class).long()#which position is the bottom layer.###[0,1,2,..,19,1,2,...,19,..]\n",
    "        \n",
    "        layer_top_logits = torch.matmul(inputs, self.layer_top_W) + self.layer_top_b###[256, 3630]\n",
    "\n",
    "        multi_bias = self.layer_bottom_b[label_position_bottom].repeat(batch_size,1)###[256,72600]\n",
    "        \n",
    "        layer_bottom_logits = torch.matmul(inputs,self.layer_bottom_W[label_position_bottom].T) + multi_bias###[256,72600]\n",
    "\n",
    "        layer_top_logits = layer_top_logits.repeat_interleave(self.ntokens_per_class,dim=1)###[256,72600]#match the top classes and the bottom classes.\n",
    "        \n",
    "        target_logits = torch.add(layer_top_logits,layer_bottom_logits)#get the final logits\n",
    "\n",
    "        return target_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:20.716957Z",
     "iopub.status.busy": "2022-11-29T06:21:20.716236Z",
     "iopub.status.idle": "2022-11-29T06:21:24.280501Z",
     "shell.execute_reply": "2022-11-29T06:21:24.279713Z",
     "shell.execute_reply.started": "2022-11-29T06:21:20.716919Z"
    }
   },
   "outputs": [],
   "source": [
    "class HMModel(nn.Module):\n",
    "    def __init__(self, article_shape):\n",
    "        super(HMModel, self).__init__()\n",
    "        \n",
    "        self.article_emb = nn.Embedding(article_shape[0], embedding_dim=article_shape[1])\n",
    "        self.hier = HierarchicalSoftmax(72582, 512,ntokens_per_class = 20)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        article_hist, week_hist = inputs[0], inputs[1]\n",
    "        x = self.article_emb(article_hist)\n",
    "        x = F.normalize(x, dim=2)###[256, 16, 512]\n",
    "        \n",
    "        x, indices = x.max(axis=1)##customer_emb[256,512]\n",
    "\n",
    "        ###get logits rather than probability to generate loss function.\n",
    "        \n",
    "        logits = self.hier(x)\n",
    "        logits = logits[:,:72582]#remove virtual leaves.\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = HMModel((len(le_article.classes_), 512))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:24.282263Z",
     "iopub.status.busy": "2022-11-29T06:21:24.281999Z",
     "iopub.status.idle": "2022-11-29T06:21:24.300014Z",
     "shell.execute_reply": "2022-11-29T06:21:24.299092Z",
     "shell.execute_reply.started": "2022-11-29T06:21:24.282227Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def calc_map(topk_preds, target_array, k=12):\n",
    "    metric = []\n",
    "    tp, fp = 0, 0\n",
    "    \n",
    "    for pred in topk_preds:\n",
    "        if target_array[pred]:\n",
    "            tp += 1\n",
    "            metric.append(tp/(tp + fp))\n",
    "        else:\n",
    "            fp += 1\n",
    "            \n",
    "    return np.sum(metric) / min(k, target_array.sum())\n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader, k=12):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    maps = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, indices = torch.topk(logits, k, dim=1)\n",
    "\n",
    "            indices = indices.detach().cpu().numpy()\n",
    "            target = target.detach().cpu().numpy()\n",
    "            \n",
    "            for i in range(indices.shape[0]):\n",
    "                maps.append(calc_map(indices[i], target[i]))\n",
    "        \n",
    "    \n",
    "    return np.mean(maps)\n",
    "\n",
    "SEQ_LEN = 16\n",
    "\n",
    "BS = 256\n",
    "NW = 8\n",
    "\n",
    "val_dataset = HMDataset(val_df, SEQ_LEN)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:21:24.302041Z",
     "iopub.status.busy": "2022-11-29T06:21:24.301502Z",
     "iopub.status.idle": "2022-11-29T06:37:56.623532Z",
     "shell.execute_reply": "2022-11-29T06:37:56.622646Z",
     "shell.execute_reply.started": "2022-11-29T06:21:24.302004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1093.7785 lr: 5e-05: 100%|██████████| 1172/1172 [01:38<00:00, 11.85it/s]\n",
      "Epoch 2 Loss: 1013.3217 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.73it/s]\n",
      "Epoch 3 Loss: 1006.2875 lr: 0.001: 100%|██████████| 1172/1172 [01:40<00:00, 11.72it/s]\n",
      "Epoch 4 Loss: 1004.8955 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.73it/s]\n",
      "Epoch 5 Loss: 1003.6794 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.81it/s]\n",
      "Epoch 6 Loss: 1002.1637 lr: 0.001: 100%|██████████| 1172/1172 [01:39<00:00, 11.84it/s]\n",
      "Epoch 7 Loss: 999.4369 lr: 0.0001: 100%|██████████| 1172/1172 [01:38<00:00, 11.84it/s]\n",
      "Epoch 8 Loss: 998.6596 lr: 0.0001: 100%|██████████| 1172/1172 [01:39<00:00, 11.83it/s]\n",
      "Epoch 9 Loss: 998.6075 lr: 0.0001: 100%|██████████| 1172/1172 [01:38<00:00, 11.88it/s]\n",
      "Epoch 10 Loss: 997.993 lr: 1e-05: 100%|██████████| 1172/1172 [01:38<00:00, 11.89it/s] \n"
     ]
    }
   ],
   "source": [
    "def dice_loss(y_pred, y_true):\n",
    "    y_pred = y_pred.sigmoid()\n",
    "    intersect = (y_true*y_pred).sum(axis=1)\n",
    "    \n",
    "    return 1 - (intersect/(intersect + y_true.sum(axis=1) + y_pred.sum(axis=1))).mean()\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs):\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    optimizer = get_optimizer(model)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    criterion = torch.nn.functional.cross_entropy\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        \n",
    "        lr = adjust_lr(optimizer, e)\n",
    "        \n",
    "        loss_list = []\n",
    "\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(inputs)\n",
    "#                 print(logits.shape)\n",
    "#                 print(logits)\n",
    "#                 print(target.shape)\n",
    "#                 print(target)\n",
    "#                 return ###\n",
    "                loss = criterion(logits, target.long())\n",
    "            #loss.backward()\n",
    "            scaler.scale(loss).backward()\n",
    "            #optimizer.step()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            \n",
    "            avg_loss = np.round(100*np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
    "            \n",
    "    return model\n",
    "\n",
    "\n",
    "MODEL_NAME = \"exp001\"\n",
    "SEED = 0\n",
    "\n",
    "train_dataset = HMDataset(train_df, SEQ_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "\n",
    "model = train(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune with more recent data for submission (include validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:37:56.626263Z",
     "iopub.status.busy": "2022-11-29T06:37:56.625672Z",
     "iopub.status.idle": "2022-11-29T06:54:10.053546Z",
     "shell.execute_reply": "2022-11-29T06:54:10.052478Z",
     "shell.execute_reply.started": "2022-11-29T06:37:56.626223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 994.2746 lr: 5e-05: 100%|██████████| 1160/1160 [01:37<00:00, 11.85it/s]\n",
      "Epoch 2 Loss: 994.0558 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.91it/s]\n",
      "Epoch 3 Loss: 991.9912 lr: 0.001: 100%|██████████| 1160/1160 [01:36<00:00, 11.96it/s]\n",
      "Epoch 4 Loss: 989.718 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s] \n",
      "Epoch 5 Loss: 987.1725 lr: 0.001: 100%|██████████| 1160/1160 [01:36<00:00, 12.05it/s]\n",
      "Epoch 6 Loss: 984.365 lr: 0.001: 100%|██████████| 1160/1160 [01:37<00:00, 11.85it/s] \n",
      "Epoch 7 Loss: 980.8309 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s]\n",
      "Epoch 8 Loss: 979.9418 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.87it/s]\n",
      "Epoch 9 Loss: 979.8323 lr: 0.0001: 100%|██████████| 1160/1160 [01:37<00:00, 11.92it/s]\n",
      "Epoch 10 Loss: 979.0787 lr: 1e-05: 100%|██████████| 1160/1160 [01:37<00:00, 11.94it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HMDataset(train_df[train_df[\"week\"] < 4].append(val_df), SEQ_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=True)\n",
    "\n",
    "model = train(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:54:10.059579Z",
     "iopub.status.busy": "2022-11-29T06:54:10.058149Z",
     "iopub.status.idle": "2022-11-29T06:54:15.542296Z",
     "shell.execute_reply": "2022-11-29T06:54:15.541386Z",
     "shell.execute_reply.started": "2022-11-29T06:54:10.059513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1371980, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...\n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...\n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...\n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv').drop(\"prediction\", axis=1)\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:54:15.544063Z",
     "iopub.status.busy": "2022-11-29T06:54:15.543800Z",
     "iopub.status.idle": "2022-11-29T06:54:21.957136Z",
     "shell.execute_reply": "2022-11-29T06:54:21.956433Z",
     "shell.execute_reply.started": "2022-11-29T06:54:15.544019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>week_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[7154]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[46435]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  week article_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...    -1     [7154]   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...    -1        NaN   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -1    [46435]   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...    -1        NaN   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...    -1        NaN   \n",
       "\n",
       "  week_history  \n",
       "0          [2]  \n",
       "1          NaN  \n",
       "2          [1]  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_test_dataset(test_df):\n",
    "    week = -1\n",
    "    test_df[\"week\"] = week\n",
    "    \n",
    "    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n",
    "    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n",
    "    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    return test_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "test_df = create_test_dataset(test_df)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:54:21.958584Z",
     "iopub.status.busy": "2022-11-29T06:54:21.958305Z",
     "iopub.status.idle": "2022-11-29T06:54:22.013981Z",
     "shell.execute_reply": "2022-11-29T06:54:22.012856Z",
     "shell.execute_reply.started": "2022-11-29T06:54:21.958529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8008965145264508"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"article_id\"].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T06:54:22.015726Z",
     "iopub.status.busy": "2022-11-29T06:54:22.015428Z",
     "iopub.status.idle": "2022-11-29T07:28:57.819641Z",
     "shell.execute_reply": "2022-11-29T07:28:57.818068Z",
     "shell.execute_reply.started": "2022-11-29T06:54:22.015689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5360/5360 [34:35<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "test_ds = HMDataset(test_df, SEQ_LEN, is_test=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n",
    "                          pin_memory=False, drop_last=False)\n",
    "\n",
    "\n",
    "def inference(model, loader, k=12):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            logits = model(inputs)\n",
    "\n",
    "            _, indices = torch.topk(logits, k, dim=1)\n",
    "\n",
    "            indices = indices.detach().cpu().numpy()\n",
    "            target = target.detach().cpu().numpy()\n",
    "\n",
    "            for i in range(indices.shape[0]):\n",
    "                preds.append(\" \".join(list(le_article.inverse_transform(indices[i]))))\n",
    "        \n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "test_df[\"prediction\"] = inference(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-29T06:18:21.024843Z",
     "iopub.status.idle": "2022-11-29T06:18:21.025741Z",
     "shell.execute_reply": "2022-11-29T06:18:21.025522Z",
     "shell.execute_reply.started": "2022-11-29T06:18:21.025498Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission.csv\", index=False, columns=[\"customer_id\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-29T07:29:44.397447Z",
     "iopub.status.busy": "2022-11-29T07:29:44.396461Z",
     "iopub.status.idle": "2022-11-29T07:29:44.416828Z",
     "shell.execute_reply": "2022-11-29T07:29:44.415843Z",
     "shell.execute_reply.started": "2022-11-29T07:29:44.397391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>week</th>\n",
       "      <th>article_id</th>\n",
       "      <th>week_history</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[7154]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0751471042 0751471041 0751471043 0751471037 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[46435]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0762846003 0915453003 0762856001 0915611003 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371975</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[27463, 28961, 33376, 45860, 49128, 6056]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>0915453004 0863581002 0915611003 0915529003 08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371976</th>\n",
       "      <td>ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371977</th>\n",
       "      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[21885, 66983, 46532, 39429]</td>\n",
       "      <td>[2, 2, 2, 1]</td>\n",
       "      <td>0762846027 0762853002 0762856008 0762846036 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371978</th>\n",
       "      <td>ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371979</th>\n",
       "      <td>ffffd9ac14e89946416d80e791d064701994755c3ab686...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0915526002 0915611003 0915529001 0915453004 09...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371980 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_id  week  \\\n",
       "0        00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...    -1   \n",
       "1        0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...    -1   \n",
       "2        000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...    -1   \n",
       "3        00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...    -1   \n",
       "4        00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...    -1   \n",
       "...                                                    ...   ...   \n",
       "1371975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...    -1   \n",
       "1371976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...    -1   \n",
       "1371977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...    -1   \n",
       "1371978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...    -1   \n",
       "1371979  ffffd9ac14e89946416d80e791d064701994755c3ab686...    -1   \n",
       "\n",
       "                                        article_id        week_history  \\\n",
       "0                                           [7154]                 [2]   \n",
       "1                                              NaN                 NaN   \n",
       "2                                          [46435]                 [1]   \n",
       "3                                              NaN                 NaN   \n",
       "4                                              NaN                 NaN   \n",
       "...                                            ...                 ...   \n",
       "1371975  [27463, 28961, 33376, 45860, 49128, 6056]  [2, 2, 2, 2, 2, 2]   \n",
       "1371976                                        NaN                 NaN   \n",
       "1371977               [21885, 66983, 46532, 39429]        [2, 2, 2, 1]   \n",
       "1371978                                        NaN                 NaN   \n",
       "1371979                                        NaN                 NaN   \n",
       "\n",
       "                                                prediction  \n",
       "0        0751471042 0751471041 0751471043 0751471037 07...  \n",
       "1        0915526002 0915611003 0915529001 0915453004 09...  \n",
       "2        0762846003 0915453003 0762856001 0915611003 08...  \n",
       "3        0915526002 0915611003 0915529001 0915453004 09...  \n",
       "4        0915526002 0915611003 0915529001 0915453004 09...  \n",
       "...                                                    ...  \n",
       "1371975  0915453004 0863581002 0915611003 0915529003 08...  \n",
       "1371976  0915526002 0915611003 0915529001 0915453004 09...  \n",
       "1371977  0762846027 0762853002 0762856008 0762846036 07...  \n",
       "1371978  0915526002 0915611003 0915529001 0915453004 09...  \n",
       "1371979  0915526002 0915611003 0915529001 0915453004 09...  \n",
       "\n",
       "[1371980 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
